{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Installs, Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install spacy==3.1.1 #restart runtime after this\n",
    "#!python -m spacy download en_core_web_sm\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import string\n",
    "import operator\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "\n",
    "#!pip install nltk\n",
    "from nltk import ngrams\n",
    "import nltk as nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('wordnet');\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('es_core_news_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2. Reading files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Data: 666\n",
      "\n",
      "Columns :  ['Filename', 'Text', 'Type', 'Year']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/alertas.csv', sep=\"|\")\n",
    "df = df[df[\"Text\"].notnull()]\n",
    "print(\"Size of Data:\", len(df))\n",
    "print()\n",
    "print(\"Columns : \", list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "exceptions = [\n",
    "    \"SAT \\n \\nSede Central Calle 55 Nº 10 32 Of 115 \\nTels 3147300 Ext 2437 Telefax 6915300 \\nEmail\", \n",
    "    \"DE LA\", \n",
    "    \"NI OTRO\", \n",
    "    \"Tels 3147300 Ext 2437 Telefax 6915300\", \n",
    "    \"Ext 2437 Telefax 6915300\", \n",
    "    \"Tels 3147300 Ext 2437 Telefax 6915300\", \n",
    "    \"Sede Central Calle 55 No\", \n",
    "    \"Tels 3147300 Ext 2437 Telefax 6915300\", \n",
    "    \"SAT Sede Central Calle 55 Nº 10 32 Of 115 Email\", \n",
    "    \"SAT Sede Central Calle 55 Nº 1032 Of 115 Email\", \n",
    "    \"SA Email\",\n",
    "    \"SAT INFORME DE RIESGO No\",\n",
    "    \"DEL CONFLICTO ARMADO Sistema\",\n",
    "    \"LA VIDA LA LIBERTAD Y\",\n",
    "    \"DELEGADA PARA LA EVALUACIÓN DEL RIESGO POBLACIÓN CIVIL\",\n",
    "    \"SAT Sede Central Calle 55 Nº 1032 Of 115 Tels 3147300 Ext 2437 Telefax 6915300 Email\", \n",
    "    \"SAT Sede Central Calle 55 Nº 10 32 Of 115 Tels 3147300 Ext 2437 Telefax 6915300 Email\", \n",
    "    \"INFORME DE RIESGO No\", \n",
    "    \"LA INTEGRIDAD FISICA DE LA POBLACIÓN\", \n",
    "    \"Tels 3147300 Ext 2437 Telefax\", \n",
    "    \"DELEGADA PARA LA EVALUACIÓN\", \n",
    "    \"LA POBLACIÓN CIVIL\", \n",
    "    \"Tels 3147300 Ext 2437 Telefax 6915300 Correo Electrónico\", \n",
    "    \"VILLEGAS Defensor Delegado\",\n",
    "    \"Tels 3147300 Ext 2452 Telefax\",\n",
    "    \"2437 Telefax\",\n",
    "    \"CHACÓN Defensor Delegado\", \n",
    "    \"Tels 3147300 ext 24372464 Fax ext 2452 Bogotá\",\n",
    "    \"Tels 3147300 Ext 2437 Telefax ext\", \n",
    "    \"Tels 3147300 Ext 2452 Telefax\", \n",
    "    \"Telefax Ext 2452 Correo Electrónico\", \n",
    "    \"2437 Telefax\", \n",
    "    \"Tels 3147300 ext 24372464 Fax ext 2452 Bogotá\", \n",
    "    \"2464 Fax ext 2452 Bogotá\",\n",
    "    \"X\", \n",
    "    \"Inminencia alta Urgente Grado 2 Urgencia intermedia Grado 3 No\", \n",
    "    \"SAT Sede Central Calle 55 Nº 1032 Bloque C Tercer piso Tels 3147300 Ext 2437 Telefax\", \n",
    "    \"O SITUACIÓN CRÓNICA\",\n",
    "    \"AUTORIDADES VINCULADAS AL\", \n",
    "    \n",
    "    \n",
    "]\n",
    "def cleantext1(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    for s in exceptions:\n",
    "        text = text.replace(s.lower(), \" \")\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text    \n",
    "\n",
    "df[\"Text\"] = df[\"Text\"].apply(cleantext1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(df[\"Text\"])\n",
    "nlp.max_length = len(text) + 100\n",
    "document = nlp (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_and_labels = [(token.text, token.pos_) for token in document if token.is_alpha]\n",
    "def get_bigrams(word_list, number_consecutive_words=2):\n",
    "    \n",
    "    ngrams = []\n",
    "    adj_length_of_word_list = len(word_list) - (number_consecutive_words - 1)\n",
    "    \n",
    "    #Loop through numbers from 0 to the (slightly adjusted) length of your word list\n",
    "    for word_index in range(adj_length_of_word_list):\n",
    "        \n",
    "        #Index the list at each number, grabbing the word at that number index as well as N number of words after it\n",
    "        ngram = word_list[word_index : word_index + number_consecutive_words]\n",
    "        \n",
    "        #Append this word combo to the master list \"ngrams\"\n",
    "        ngrams.append(ngram)\n",
    "        \n",
    "    return ngrams\n",
    "\n",
    "bigrams = get_bigrams(tokens_and_labels)\n",
    "\n",
    "def get_neighbor_words(keyword, bigrams, pos_label = None):\n",
    "    \n",
    "    neighbor_words = []\n",
    "    keyword = keyword.lower()\n",
    "    \n",
    "    for bigram in bigrams:\n",
    "        \n",
    "        #Extract just the lowercased words (not the labels) for each bigram\n",
    "        words = [word.lower() for word, label in bigram]        \n",
    "        \n",
    "        #Check to see if keyword is in the bigram\n",
    "        if keyword in words:\n",
    "            \n",
    "            for word, label in bigram:\n",
    "                \n",
    "                #Now focus on the neighbor word, not the keyword\n",
    "                if word.lower() != keyword:\n",
    "                    #If the neighbor word matches the right pos_label, append it to the master list\n",
    "                    if label == pos_label or pos_label == None:\n",
    "                        neighbor_words.append(word.lower())\n",
    "    \n",
    "    return Counter(neighbor_words).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjetivos cerca de Protección "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('deprevención', 6),\n",
       " ('individual', 5),\n",
       " ('colectiva', 5),\n",
       " ('especial', 4),\n",
       " ('preventiva', 4)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_neighbor_words(\"protección\", bigrams, \"ADJ\")[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verbos cerca de proteccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('señala', 2),\n",
       " ('obtener', 2),\n",
       " ('deprevención', 2),\n",
       " ('hacer', 2),\n",
       " ('brindando', 2),\n",
       " ('contin', 1),\n",
       " ('generar', 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_neighbor_words(\"protección\", bigrams, \"VERB\")[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nouns cerca de protección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prevención', 8),\n",
       " ('investigación', 8),\n",
       " ('líderes', 2),\n",
       " ('auto', 2),\n",
       " ('tierra', 2),\n",
       " ('medidas', 2)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_neighbor_words(\"protección\", bigrams, \"NOUN\")[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exporting to html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 5_NLP_Word_Tokenization.ipynb to html\n",
      "[NbConvertApp] Writing 706150 bytes to 5_NLP_Word_Tokenization.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html 5_NLP_Word_Tokenization.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

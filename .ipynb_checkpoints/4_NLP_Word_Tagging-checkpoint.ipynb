{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Installs, Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install spacy==3.1.1 \n",
    "#restart runtime after this\n",
    "#!python -m spacy download es_core_news_lg\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"es_core_news_lg\")\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import string\n",
    "import operator\n",
    "from itertools import islice\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2. Reading files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Data: 666\n",
      "\n",
      "Columns :  ['Filename', 'Text', 'Type', 'Year']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/alertas.csv', sep=\"|\")\n",
    "df = df[df[\"Text\"] != \" \"]\n",
    "print(\"Size of Data:\", len(df))\n",
    "print()\n",
    "print(\"Columns : \", list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw = [\"'s\", \"s\", \"@\", '*', '’', \"t\", \"gt\", \"http\", \"https\", \"amp\", \"m\", 'i', 'u', 'youtu.be/Sj9uLcw-yl4', \n",
    "        \"'m\", '\\-', '[', ']', '·', 're', '“', '”']\n",
    "#m is the number of top ngrams.\n",
    "def getNPartsOfSpeech(text, m, tag):\n",
    "    #lemmatization and filtering allowed tags\n",
    "    filtered_tags = []\n",
    "    \n",
    "    nlp.max_length = len(text) + 100\n",
    "    doc = nlp(text)\n",
    "\n",
    "    for token in doc:\n",
    "        if token.tag_.startswith(tag): \n",
    "            filtered_tags.append([token.lemma_, token.tag_])\n",
    "    dt = pd.Dataframe(filtered_tags, columns=['word', 'tag'])\n",
    "    dt = dt.groupby(['word', 'tag']).count().sort_values(ascending=False)\n",
    "    return dt[:m]    \n",
    "    \n",
    "\n",
    "def printNPOS(data, m):\n",
    "    postags = []\n",
    "    \n",
    "    verbs = getNPartsOfSpeech(data, m, 'V')\n",
    "    verbs += [(None, None)] * (m - len(verbs))\n",
    "    \n",
    "    adjs = getNPartsOfSpeech(data, m , 'J')\n",
    "    adjs +=[(None, None)] * (m - len(adjs))\n",
    "    \n",
    "    nouns = getNPartsOfSpeech(data, m , 'N')\n",
    "    nouns +=[(None, None)] * (m - len(nouns))\n",
    "    \n",
    "    for i in range(0,m):\n",
    "        if all(verbs[i]) or all(adj[i]) or all(nouns[i]):\n",
    "            postags.append(verbs[i] + adjs[i] + nouns[i])\n",
    "    df = pd.DataFrame(postags, columns=['Verbs', 'Absolute Freq', 'Relative Freq', \n",
    "                                       'Adjectives', 'Absolute Freq', 'Relative Freq',\n",
    "                                        'Nouns', 'Absolute Freq', 'Relative Freq' ]) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tags = []\n",
    "text = ' '.join(df['Text'])  \n",
    "nlp.max_length = len(text) + 100\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    if token.tag_.startswith(tag): \n",
    "        filtered_tags.append([token.lemma_, token.tag_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.Dataframe(filtered_tags, columns=['word', 'tag'])\n",
    "dt = dt.groupby(['word', 'tag']).count().sort_values(ascending=False)\n",
    "return dt[:m] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgetNPartsOfSpeech\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mText\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mV\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mgetNPartsOfSpeech\u001b[1;34m(text, m, tag)\u001b[0m\n\u001b[0;32m      6\u001b[0m filtered_tags \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m nlp\u001b[38;5;241m.\u001b[39mmax_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(text) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m----> 9\u001b[0m doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mtag_\u001b[38;5;241m.\u001b[39mstartswith(tag): \n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py:1005\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    986\u001b[0m     text: Union[\u001b[38;5;28mstr\u001b[39m, Doc],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    989\u001b[0m     component_cfg: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    990\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Doc:\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;124;03m\"\"\"Apply the pipeline to some text. The text can span multiple sentences,\u001b[39;00m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;124;03m    and can contain arbitrary whitespace. Alignment into the original string\u001b[39;00m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;124;03m    is preserved.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;124;03m    DOCS: https://spacy.io/api/language#call\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1005\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1006\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m component_cfg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1007\u001b[0m         component_cfg \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py:1095\u001b[0m, in \u001b[0;36mLanguage._ensure_doc\u001b[1;34m(self, doc_like)\u001b[0m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m doc_like\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc_like, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m-> 1095\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc_like\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE866\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(doc_like)))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py:1088\u001b[0m, in \u001b[0;36mLanguage.make_doc\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length:\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1086\u001b[0m         Errors\u001b[38;5;241m.\u001b[39mE088\u001b[38;5;241m.\u001b[39mformat(length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(text), max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length)\n\u001b[0;32m   1087\u001b[0m     )\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\tokenizer.pyx:143\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\tokenizer.pyx:179\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer._tokenize_affixes\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\tokenizer.pyx:383\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer._tokenize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\tokenizer.pyx:461\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer._attach_tokens\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\vocab.pyx:159\u001b[0m, in \u001b[0;36mspacy.vocab.Vocab.get\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\vocab.pyx:196\u001b[0m, in \u001b[0;36mspacy.vocab.Vocab._new_lexeme\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\lang\\lex_attrs.py:146\u001b[0m, in \u001b[0;36mlower\u001b[1;34m(string)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlower\u001b[39m(string: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstring\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "getNPartsOfSpeech(' '.join(df['Text']), 10, 'V')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Top 20 Verbs, Adj, and Nouns in the whole corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Verbs</th>\n",
       "      <th>Absolute Freq</th>\n",
       "      <th>Relative Freq</th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Absolute Freq</th>\n",
       "      <th>Relative Freq</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Absolute Freq</th>\n",
       "      <th>Relative Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y</td>\n",
       "      <td>14311</td>\n",
       "      <td>5.87</td>\n",
       "      <td>los</td>\n",
       "      <td>19216</td>\n",
       "      <td>4.59</td>\n",
       "      <td>y</td>\n",
       "      <td>82741</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>el</td>\n",
       "      <td>9997</td>\n",
       "      <td>4.10</td>\n",
       "      <td>un</td>\n",
       "      <td>16615</td>\n",
       "      <td>3.97</td>\n",
       "      <td>la</td>\n",
       "      <td>65256</td>\n",
       "      <td>2.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>que</td>\n",
       "      <td>5750</td>\n",
       "      <td>2.36</td>\n",
       "      <td>las</td>\n",
       "      <td>16007</td>\n",
       "      <td>3.83</td>\n",
       "      <td>que</td>\n",
       "      <td>50737</td>\n",
       "      <td>2.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>se</td>\n",
       "      <td>5519</td>\n",
       "      <td>2.27</td>\n",
       "      <td>el</td>\n",
       "      <td>13066</td>\n",
       "      <td>3.12</td>\n",
       "      <td>el</td>\n",
       "      <td>36618</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>4772</td>\n",
       "      <td>1.96</td>\n",
       "      <td>que</td>\n",
       "      <td>12648</td>\n",
       "      <td>3.02</td>\n",
       "      <td>con</td>\n",
       "      <td>32216</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>del</td>\n",
       "      <td>4740</td>\n",
       "      <td>1.95</td>\n",
       "      <td>una</td>\n",
       "      <td>12548</td>\n",
       "      <td>3.00</td>\n",
       "      <td>del</td>\n",
       "      <td>28036</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>para</td>\n",
       "      <td>4689</td>\n",
       "      <td>1.92</td>\n",
       "      <td>y</td>\n",
       "      <td>9785</td>\n",
       "      <td>2.34</td>\n",
       "      <td>por</td>\n",
       "      <td>24685</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>las</td>\n",
       "      <td>4307</td>\n",
       "      <td>1.77</td>\n",
       "      <td>civil</td>\n",
       "      <td>7812</td>\n",
       "      <td>1.87</td>\n",
       "      <td>para</td>\n",
       "      <td>24152</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>por</td>\n",
       "      <td>3277</td>\n",
       "      <td>1.35</td>\n",
       "      <td>se</td>\n",
       "      <td>7555</td>\n",
       "      <td>1.81</td>\n",
       "      <td>los</td>\n",
       "      <td>22271</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>con</td>\n",
       "      <td>2922</td>\n",
       "      <td>1.20</td>\n",
       "      <td>la</td>\n",
       "      <td>6729</td>\n",
       "      <td>1.61</td>\n",
       "      <td>las</td>\n",
       "      <td>20749</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>al</td>\n",
       "      <td>2774</td>\n",
       "      <td>1.14</td>\n",
       "      <td>por</td>\n",
       "      <td>5571</td>\n",
       "      <td>1.33</td>\n",
       "      <td>El</td>\n",
       "      <td>17216</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>como</td>\n",
       "      <td>2593</td>\n",
       "      <td>1.06</td>\n",
       "      <td>al</td>\n",
       "      <td>4725</td>\n",
       "      <td>1.13</td>\n",
       "      <td>La</td>\n",
       "      <td>17079</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>e</td>\n",
       "      <td>2254</td>\n",
       "      <td>0.93</td>\n",
       "      <td>contra</td>\n",
       "      <td>4670</td>\n",
       "      <td>1.12</td>\n",
       "      <td>como</td>\n",
       "      <td>17060</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>los</td>\n",
       "      <td>2211</td>\n",
       "      <td>0.91</td>\n",
       "      <td>grupos</td>\n",
       "      <td>4250</td>\n",
       "      <td>1.02</td>\n",
       "      <td>se</td>\n",
       "      <td>16965</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>armados</td>\n",
       "      <td>2181</td>\n",
       "      <td>0.90</td>\n",
       "      <td>social</td>\n",
       "      <td>4078</td>\n",
       "      <td>0.97</td>\n",
       "      <td>En</td>\n",
       "      <td>10497</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>•</td>\n",
       "      <td>1952</td>\n",
       "      <td>0.80</td>\n",
       "      <td>lo</td>\n",
       "      <td>3687</td>\n",
       "      <td>0.88</td>\n",
       "      <td>al</td>\n",
       "      <td>9533</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>o</td>\n",
       "      <td>1750</td>\n",
       "      <td>0.72</td>\n",
       "      <td>rural</td>\n",
       "      <td>3623</td>\n",
       "      <td>0.87</td>\n",
       "      <td>San</td>\n",
       "      <td>9252</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>la</td>\n",
       "      <td>1567</td>\n",
       "      <td>0.64</td>\n",
       "      <td>cual</td>\n",
       "      <td>3315</td>\n",
       "      <td>0.79</td>\n",
       "      <td>su</td>\n",
       "      <td>9030</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>es</td>\n",
       "      <td>1553</td>\n",
       "      <td>0.64</td>\n",
       "      <td>en</td>\n",
       "      <td>3213</td>\n",
       "      <td>0.77</td>\n",
       "      <td>ilegales</td>\n",
       "      <td>8032</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>entre</td>\n",
       "      <td>1508</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10-32</td>\n",
       "      <td>2590</td>\n",
       "      <td>0.62</td>\n",
       "      <td>ha</td>\n",
       "      <td>7968</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Verbs  Absolute Freq  Relative Freq Adjectives  Absolute Freq  \\\n",
       "0         y          14311           5.87        los          19216   \n",
       "1        el           9997           4.10         un          16615   \n",
       "2       que           5750           2.36        las          16007   \n",
       "3        se           5519           2.27         el          13066   \n",
       "4        en           4772           1.96        que          12648   \n",
       "5       del           4740           1.95        una          12548   \n",
       "6      para           4689           1.92          y           9785   \n",
       "7       las           4307           1.77      civil           7812   \n",
       "8       por           3277           1.35         se           7555   \n",
       "9       con           2922           1.20         la           6729   \n",
       "10       al           2774           1.14        por           5571   \n",
       "11     como           2593           1.06         al           4725   \n",
       "12        e           2254           0.93     contra           4670   \n",
       "13      los           2211           0.91     grupos           4250   \n",
       "14  armados           2181           0.90     social           4078   \n",
       "15        •           1952           0.80         lo           3687   \n",
       "16        o           1750           0.72      rural           3623   \n",
       "17       la           1567           0.64       cual           3315   \n",
       "18       es           1553           0.64         en           3213   \n",
       "19    entre           1508           0.62      10-32           2590   \n",
       "\n",
       "    Relative Freq     Nouns  Absolute Freq  Relative Freq  \n",
       "0            4.59         y          82741           3.53  \n",
       "1            3.97        la          65256           2.78  \n",
       "2            3.83       que          50737           2.16  \n",
       "3            3.12        el          36618           1.56  \n",
       "4            3.02       con          32216           1.37  \n",
       "5            3.00       del          28036           1.20  \n",
       "6            2.34       por          24685           1.05  \n",
       "7            1.87      para          24152           1.03  \n",
       "8            1.81       los          22271           0.95  \n",
       "9            1.61       las          20749           0.89  \n",
       "10           1.33        El          17216           0.73  \n",
       "11           1.13        La          17079           0.73  \n",
       "12           1.12      como          17060           0.73  \n",
       "13           1.02        se          16965           0.72  \n",
       "14           0.97        En          10497           0.45  \n",
       "15           0.88        al           9533           0.41  \n",
       "16           0.87       San           9252           0.39  \n",
       "17           0.79        su           9030           0.39  \n",
       "18           0.77  ilegales           8032           0.34  \n",
       "19           0.62        ha           7968           0.34  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printNPOS(' '.join(df['Text']), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Top 20 Verbs, Adj, and Nouns in Advertencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = df[df[\"Type\"] == \"advertencia\"]\n",
    "printNPOS(' '.join(dfg['Text']), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Top 20 Verbs, Adj, and Nouns in Seguimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = df[df[\"Type\"] == \"seguimiento\"]\n",
    "printNPOS(' '.join(dfg['Text']), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exporting to html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 8_NLP_Word_Tagging.ipynb to html\n",
      "[NbConvertApp] Writing 586885 bytes to 8_NLP_Word_Tagging.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

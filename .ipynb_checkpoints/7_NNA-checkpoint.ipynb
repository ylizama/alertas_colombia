{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fd4b156",
   "metadata": {},
   "source": [
    "# 1. Install, Imports, Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9213a640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "#!pip install rake_nltk\n",
    "#!python -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2550cf0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from spacy.lang.es.examples import sentences \n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "from IPython.display import Markdown, display\n",
    "import string, math\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from rake_nltk import Rake\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a2612f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10, 6]\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "punct = string.punctuation +'”“'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21e3781",
   "metadata": {},
   "source": [
    "# 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fd3dc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of documents: 1753\n",
      "Number of documents with no accesible text (password protected): 5\n",
      "Number of documents with accesible text: 1748\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/alertas.csv\", sep=\"|\")\n",
    "\n",
    "print(\"Total Number of documents:\", len(df))\n",
    "print(\"Number of documents with no accesible text (password protected):\", len(df[df['Text'].isnull()]))\n",
    "print(\"Number of documents with accesible text:\",  len(df[df['Text'].notnull()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fa63b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "      <th>Subtype</th>\n",
       "      <th>Type</th>\n",
       "      <th>Year</th>\n",
       "      <th>Path</th>\n",
       "      <th>Departamento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT N° 003-18 NAR-Cumbitara, Maguí Payán, Polic...</td>\n",
       "      <td>Defensoria del Pueblo COLOMB IA Bogotá D.C., 5...</td>\n",
       "      <td>Alerta Temprana</td>\n",
       "      <td>Advertencia</td>\n",
       "      <td>2018</td>\n",
       "      <td>data\\Advertencia_PDF\\AT 2018\\AT N° 003-18 NAR-...</td>\n",
       "      <td>Nariño</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT N° 004-18 NAR-Tumaco.pdf</td>\n",
       "      <td>Defensoría del Pueblo CO LO Mll.t. Carrera 9 #...</td>\n",
       "      <td>Alerta Temprana</td>\n",
       "      <td>Advertencia</td>\n",
       "      <td>2018</td>\n",
       "      <td>data\\Advertencia_PDF\\AT 2018\\AT N° 004-18 NAR-...</td>\n",
       "      <td>Nariño</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT N° 005-18 COR-Tierralta.pdf</td>\n",
       "      <td>Carrera 9 # 16 -21 Bogotá D.C. PBX: (57) (1) 3...</td>\n",
       "      <td>Alerta Temprana</td>\n",
       "      <td>Advertencia</td>\n",
       "      <td>2018</td>\n",
       "      <td>data\\Advertencia_PDF\\AT 2018\\AT N° 005-18 COR-...</td>\n",
       "      <td>Córdoba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT N° 006-18 ARA-Saravena.pdf</td>\n",
       "      <td>Defensoría del Pueblo Carrera 9 # 16-21 Bogotá...</td>\n",
       "      <td>Alerta Temprana</td>\n",
       "      <td>Advertencia</td>\n",
       "      <td>2018</td>\n",
       "      <td>data\\Advertencia_PDF\\AT 2018\\AT N° 006-18 ARA-...</td>\n",
       "      <td>Arauca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT N° 007-18 MET-Puerto Lleras, Puerto Rico y ...</td>\n",
       "      <td>San Vicente Bajo l' Margen Izquierda del río G...</td>\n",
       "      <td>Alerta Temprana</td>\n",
       "      <td>Advertencia</td>\n",
       "      <td>2018</td>\n",
       "      <td>data\\Advertencia_PDF\\AT 2018\\AT N° 007-18 MET-...</td>\n",
       "      <td>Meta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filename  \\\n",
       "0  AT N° 003-18 NAR-Cumbitara, Maguí Payán, Polic...   \n",
       "1                        AT N° 004-18 NAR-Tumaco.pdf   \n",
       "2                     AT N° 005-18 COR-Tierralta.pdf   \n",
       "3                      AT N° 006-18 ARA-Saravena.pdf   \n",
       "4  AT N° 007-18 MET-Puerto Lleras, Puerto Rico y ...   \n",
       "\n",
       "                                                Text          Subtype  \\\n",
       "0  Defensoria del Pueblo COLOMB IA Bogotá D.C., 5...  Alerta Temprana   \n",
       "1  Defensoría del Pueblo CO LO Mll.t. Carrera 9 #...  Alerta Temprana   \n",
       "2  Carrera 9 # 16 -21 Bogotá D.C. PBX: (57) (1) 3...  Alerta Temprana   \n",
       "3  Defensoría del Pueblo Carrera 9 # 16-21 Bogotá...  Alerta Temprana   \n",
       "4  San Vicente Bajo l' Margen Izquierda del río G...  Alerta Temprana   \n",
       "\n",
       "          Type  Year                                               Path  \\\n",
       "0  Advertencia  2018  data\\Advertencia_PDF\\AT 2018\\AT N° 003-18 NAR-...   \n",
       "1  Advertencia  2018  data\\Advertencia_PDF\\AT 2018\\AT N° 004-18 NAR-...   \n",
       "2  Advertencia  2018  data\\Advertencia_PDF\\AT 2018\\AT N° 005-18 COR-...   \n",
       "3  Advertencia  2018  data\\Advertencia_PDF\\AT 2018\\AT N° 006-18 ARA-...   \n",
       "4  Advertencia  2018  data\\Advertencia_PDF\\AT 2018\\AT N° 007-18 MET-...   \n",
       "\n",
       "  Departamento  \n",
       "0       Nariño  \n",
       "1       Nariño  \n",
       "2      Córdoba  \n",
       "3       Arauca  \n",
       "4         Meta  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c113e82",
   "metadata": {},
   "source": [
    "# 3 Cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "673a6eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f758cbca",
   "metadata": {},
   "source": [
    "# 4. Extracting NNA Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a40bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "children_keywords = [\"NNAJ\", \"niños\", \"niñas\", \"adolescentes\", \"jóvenes\", \"NNA\"]\n",
    "agressions = ['homicidio', 'masacres', 'desplazamiento', 'desaparición forzada',] \n",
    "uso_recl = ['reclutamiento', 'expendio de droga', 'sicariato', \"cobro de 'vacunas'\", \"vigilancia\", \n",
    "            \"acciones ejemplarizates\", \"utilización ilícita\", \"uso ilícito\", \"drogas ilícitas\", \"prácticas sexuales\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b4710f",
   "metadata": {},
   "source": [
    "# 4.1. Example of sentences that include use of NNAJ in the first 20 docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a03354d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "text = ' '.join(df[df[\"Text\"].notnull()]['Text'][:10])\n",
    "keyword = \" NNAJ \"\n",
    "    \n",
    "document = nlp(text)\n",
    "for sentence in document.sents:\n",
    "    sentence = sentence.text\n",
    "  \n",
    "    if keyword.lower() in sentence.lower():\n",
    "            \n",
    "            #Use the regex library to replace linebreaks and to make the keyword bolded, again ignoring capitalization\n",
    "            sentence = re.sub('\\n', ' ', sentence)\n",
    "            sentence = re.sub(f\"{keyword}\", f\"**{keyword}**\", sentence, flags=re.IGNORECASE)\n",
    "            \n",
    "            display(Markdown(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4064308e",
   "metadata": {},
   "source": [
    "# 4.2 Extracting NNA sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a564dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentences_with_keyword(keywords, document):\n",
    "    sents = []\n",
    "    \n",
    "    #Iterate through all the sentences in the document and pull out the text of each sentence\n",
    "    for sentence in document.sents:\n",
    "        sentence = sentence.text\n",
    "        \n",
    "        for keyword in keywords: \n",
    "            if keyword.lower() in sentence.lower():\n",
    "            \n",
    "                #Use the regex library to replace linebreaks and to make the keyword bolded, again ignoring capitalization\n",
    "                sentence = re.sub('\\n', ' ', sentence)\n",
    "                sentence = re.sub(f\"{keyword}\", f\"**{keyword}**\", sentence, flags=re.IGNORECASE)\n",
    "                sents.append(sentence)\n",
    "                break           \n",
    "    return sents\n",
    "\n",
    "def extract_NNAJ_sentences(text):\n",
    "    if text != text:\n",
    "        return []\n",
    "    document = nlp(text)\n",
    "    return find_sentences_with_keyword(keywords=children_keywords, document=document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e58e2d28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df['NNAJ'] = df['Text'].apply(extract_NNAJ_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c9e78",
   "metadata": {},
   "source": [
    "# 5. Saving partial text in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6fc7efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"data/alertas_NNA_sentences.csv\", sep=\"|\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47cafa5",
   "metadata": {},
   "source": [
    "# 6. Extract information around NNAJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "433108a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/alertas_NNA_sentences.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f80b30a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Filename', 'Text', 'Subtype', 'Type', 'Year', 'Path', 'Departamento',\n",
       "       'NNAJ'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9457100",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://www.analyticsvidhya.com/blog/2022/03/keyword-extraction-methods-from-documents-in-nlp/\n",
    "#https://towardsdatascience.com/keyword-extraction-process-in-python-with-natural-language-processing-nlp-d769a9069d5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "30474d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "rake_nltk_var = Rake(language='spanish')\n",
    "\n",
    "def extract_NNAJ_keywords(text):\n",
    "    sentences = text.strip(\"']['\").split(\"', '\")\n",
    "   \n",
    "    if len(sentences) == 0:\n",
    "        return []\n",
    "    \n",
    "    keywords_extracted = []\n",
    "    for sent in sentences:\n",
    "        #remove punctuation\n",
    "        s = sent.translate(str.maketrans('', '', string.punctuation + '”“·'))\n",
    "        s = s.replace(\" s \", \" \")\n",
    "        rake_nltk_var.extract_keywords_from_text(s)\n",
    "        keywords_extracted += rake_nltk_var.get_ranked_phrases()\n",
    "    return keywords_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59a5e51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NNAJ_keywords'] = df['NNAJ'].apply(extract_NNAJ_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1376f084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "      <th>Subtype</th>\n",
       "      <th>Type</th>\n",
       "      <th>Year</th>\n",
       "      <th>Path</th>\n",
       "      <th>Departamento</th>\n",
       "      <th>NNAJ</th>\n",
       "      <th>NNAJ_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT N° 003-18 NAR-Cumbitara, Maguí Payán, Polic...</td>\n",
       "      <td>Defensoria del Pueblo COLOMB IA Bogotá D.C., 5...</td>\n",
       "      <td>Alerta Temprana</td>\n",
       "      <td>Advertencia</td>\n",
       "      <td>2018</td>\n",
       "      <td>data\\Advertencia_PDF\\AT 2018\\AT N° 003-18 NAR-...</td>\n",
       "      <td>Nariño</td>\n",
       "      <td>['Por lo anterior; desde el Sistema de Alertas...</td>\n",
       "      <td>[amenazas asesinatos selectivos desplazamiento...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT N° 004-18 NAR-Tumaco.pdf</td>\n",
       "      <td>Defensoría del Pueblo CO LO Mll.t. Carrera 9 #...</td>\n",
       "      <td>Alerta Temprana</td>\n",
       "      <td>Advertencia</td>\n",
       "      <td>2018</td>\n",
       "      <td>data\\Advertencia_PDF\\AT 2018\\AT N° 004-18 NAR-...</td>\n",
       "      <td>Nariño</td>\n",
       "      <td>['Los territorios dejados por las FARC - EP, f...</td>\n",
       "      <td>[armas antiguos integrantes desmovilizados, gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT N° 005-18 COR-Tierralta.pdf</td>\n",
       "      <td>Carrera 9 # 16 -21 Bogotá D.C. PBX: (57) (1) 3...</td>\n",
       "      <td>Alerta Temprana</td>\n",
       "      <td>Advertencia</td>\n",
       "      <td>2018</td>\n",
       "      <td>data\\Advertencia_PDF\\AT 2018\\AT N° 005-18 COR-...</td>\n",
       "      <td>Córdoba</td>\n",
       "      <td>['En ese sentido, la población civil se encuen...</td>\n",
       "      <td>[carrera 9 16 21 bogotá dc pbx 57 1 3147300 lí...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT N° 006-18 ARA-Saravena.pdf</td>\n",
       "      <td>Defensoría del Pueblo Carrera 9 # 16-21 Bogotá...</td>\n",
       "      <td>Alerta Temprana</td>\n",
       "      <td>Advertencia</td>\n",
       "      <td>2018</td>\n",
       "      <td>data\\Advertencia_PDF\\AT 2018\\AT N° 006-18 ARA-...</td>\n",
       "      <td>Arauca</td>\n",
       "      <td>['También se advierte· el riesgo de secuestros...</td>\n",
       "      <td>[ocasionan daños considerables, utilización il...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT N° 007-18 MET-Puerto Lleras, Puerto Rico y ...</td>\n",
       "      <td>San Vicente Bajo l' Margen Izquierda del río G...</td>\n",
       "      <td>Alerta Temprana</td>\n",
       "      <td>Advertencia</td>\n",
       "      <td>2018</td>\n",
       "      <td>data\\Advertencia_PDF\\AT 2018\\AT N° 007-18 MET-...</td>\n",
       "      <td>Meta</td>\n",
       "      <td>['Integrantes del Nuev o Partido FAR( **niños*...</td>\n",
       "      <td>[jóv enes campesinos pobres docentes habita nt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filename  \\\n",
       "0  AT N° 003-18 NAR-Cumbitara, Maguí Payán, Polic...   \n",
       "1                        AT N° 004-18 NAR-Tumaco.pdf   \n",
       "2                     AT N° 005-18 COR-Tierralta.pdf   \n",
       "3                      AT N° 006-18 ARA-Saravena.pdf   \n",
       "4  AT N° 007-18 MET-Puerto Lleras, Puerto Rico y ...   \n",
       "\n",
       "                                                Text          Subtype  \\\n",
       "0  Defensoria del Pueblo COLOMB IA Bogotá D.C., 5...  Alerta Temprana   \n",
       "1  Defensoría del Pueblo CO LO Mll.t. Carrera 9 #...  Alerta Temprana   \n",
       "2  Carrera 9 # 16 -21 Bogotá D.C. PBX: (57) (1) 3...  Alerta Temprana   \n",
       "3  Defensoría del Pueblo Carrera 9 # 16-21 Bogotá...  Alerta Temprana   \n",
       "4  San Vicente Bajo l' Margen Izquierda del río G...  Alerta Temprana   \n",
       "\n",
       "          Type  Year                                               Path  \\\n",
       "0  Advertencia  2018  data\\Advertencia_PDF\\AT 2018\\AT N° 003-18 NAR-...   \n",
       "1  Advertencia  2018  data\\Advertencia_PDF\\AT 2018\\AT N° 004-18 NAR-...   \n",
       "2  Advertencia  2018  data\\Advertencia_PDF\\AT 2018\\AT N° 005-18 COR-...   \n",
       "3  Advertencia  2018  data\\Advertencia_PDF\\AT 2018\\AT N° 006-18 ARA-...   \n",
       "4  Advertencia  2018  data\\Advertencia_PDF\\AT 2018\\AT N° 007-18 MET-...   \n",
       "\n",
       "  Departamento                                               NNAJ  \\\n",
       "0       Nariño  ['Por lo anterior; desde el Sistema de Alertas...   \n",
       "1       Nariño  ['Los territorios dejados por las FARC - EP, f...   \n",
       "2      Córdoba  ['En ese sentido, la población civil se encuen...   \n",
       "3       Arauca  ['También se advierte· el riesgo de secuestros...   \n",
       "4         Meta  ['Integrantes del Nuev o Partido FAR( **niños*...   \n",
       "\n",
       "                                       NNAJ_keywords  \n",
       "0  [amenazas asesinatos selectivos desplazamiento...  \n",
       "1  [armas antiguos integrantes desmovilizados, gr...  \n",
       "2  [carrera 9 16 21 bogotá dc pbx 57 1 3147300 lí...  \n",
       "3  [ocasionan daños considerables, utilización il...  \n",
       "4  [jóv enes campesinos pobres docentes habita nt...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a4f6e6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_imp_words = ['fiestas', 'amenazas', 'asesinatos selectivos', 'desplazamientos individuales',  'reclutamientos forzados', \n",
    "                 'desplazamientos masivos', 'restricciones movilidad', 'desaparición forzada',\n",
    "                  'confinamientos', 'combates', 'ataques indiscriminados']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cef106a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Por lo anterior; desde el Sistema de Alertas Tempranas, advertimos ante la inminencia de violacion masivas a los derechos humanos e infracciones al DIH como amenazas, asesinatos selectivos, desplazamientos individuales, reclutamientos forzados y utilización ilícita de **niños**, niñas y adolescentes, desplazamientos masivos, restricciones a la movilidad, desaparición forzada, confinamientos, combates con interposición de la población civil, ataques indiscriminados, entre otras.\n",
      "\n",
      "RECOMENDACIONES A la Secretaria Técnica de la CIPRAT, inicié el seguimiento del impacto de las medidas adoptadas y a la continuidad del riesgo, y en coordinación con la Gobernación de Nariño y las alcaldías municipales de Policarpa, Cumbitara, Magüí Payán y Roberto Payán convoque a la instancia territorial o instancias territoriales con este mismo propósito, teniendo en cuenta el enfoque territorial, diferencial étnico y de género establecidos en el decreto 2<1,24 a 017, con el fin de promover y adoptar medidas efectivas de protección ante nuevas s·tuacion s de riesgo y amenaza contra la población civil, especialmente, a favor de líderes sociale ujetos de especial protección constitucional como **niños**, niñas, adolescentes y j0v,e población en situación de desplazamiento forzado y otros grupos poblacionales en sit1:1 ci.é_n de riesgo.\n",
      "\n",
      "A la Comisión lntersectorial para la prevención del reclutamiento y la utilización de **niños**, niñas, adolescentes y jóvenes por grupos armados ilegales para que con el co1KllfS de las instancias que conforman el Sistema Nacional de Bienestar Familiar, o dinen las acciones necesarias, en términos de políticas y estrategias para prevenir el r -ecluta;niento forzado de **niños**, niñas, adolescentes y jóvenes por parte de actores ar atlas ·legales en las zonas rurales de los municipios de Policarpa, Cumbitara, Magüí PaY,áfl y · alerto Payán.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['amenazas asesinatos selectivos desplazamientos individuales reclutamientos forzados',\n",
       " 'movilidad desaparición forzada confinamientos combates',\n",
       " 'adolescentes desplazamientos masivos restricciones',\n",
       " 'población civil ataques indiscriminados',\n",
       " 'alertas tempranas advertimos',\n",
       " 'violacion masivas',\n",
       " 'utilización ilícita',\n",
       " 'niños niñas',\n",
       " 'derechos humanos',\n",
       " 'sistema',\n",
       " 'interposición',\n",
       " 'inminencia',\n",
       " 'infracciones',\n",
       " 'dih',\n",
       " 'anterior',\n",
       " 'policarpa cumbitara magüí payán',\n",
       " 'enfoque territorial diferencial étnico',\n",
       " 'roberto payán convoque',\n",
       " 'niños niñas adolescentes',\n",
       " 'líderes sociale ujetos',\n",
       " 'población civil especialmente',\n",
       " 'adoptar medidas efectivas',\n",
       " 'especial protección constitucional',\n",
       " 'instancia territorial',\n",
       " 'medidas adoptadas',\n",
       " 'j0ve población',\n",
       " 'sit11 cién',\n",
       " 'secretaria técnica',\n",
       " 'nuevas stuacion',\n",
       " 'mismo propósito',\n",
       " 'instancias territoriales',\n",
       " 'género establecidos',\n",
       " 'grupos poblacionales',\n",
       " 'desplazamiento forzado',\n",
       " 'decreto 2124',\n",
       " 'ciprat inicié',\n",
       " 'alcaldías municipales',\n",
       " 'protección',\n",
       " 'situación',\n",
       " 'seguimiento',\n",
       " 'riesgo',\n",
       " 'riesgo',\n",
       " 'riesgo',\n",
       " 'recomendaciones',\n",
       " 'promover',\n",
       " 'nariño',\n",
       " 'impacto',\n",
       " 'gobernación',\n",
       " 'fin',\n",
       " 'favor',\n",
       " 'cuenta',\n",
       " 'coordinación',\n",
       " 'continuidad',\n",
       " 'amenaza',\n",
       " '017',\n",
       " 'policarpa cumbitara magüí payáfl',\n",
       " 'actores ar atlas legales',\n",
       " 'r eclutaniento forzado',\n",
       " 'niños niñas adolescentes',\n",
       " 'niños niñas adolescentes',\n",
       " 'grupos armados ilegales',\n",
       " 'zonas rurales',\n",
       " 'sistema nacional',\n",
       " 'comisión lntersectorial',\n",
       " 'bienestar familiar',\n",
       " 'alerto payán',\n",
       " 'acciones necesarias',\n",
       " 'utilización',\n",
       " 'términos',\n",
       " 'reclutamiento',\n",
       " 'prevenir',\n",
       " 'prevención',\n",
       " 'políticas',\n",
       " 'parte',\n",
       " 'municipios',\n",
       " 'jóvenes',\n",
       " 'jóvenes',\n",
       " 'instancias',\n",
       " 'estrategias',\n",
       " 'dinen',\n",
       " 'conforman',\n",
       " 'co1kllfs']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for s in df.loc[0]['NNAJ'].strip(\"']['\").split(\"', '\"):\n",
    "    print(s)\n",
    "    print('')\n",
    "    \n",
    "extract_NNAJ_keywords(df.loc[0]['NNAJ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cda42ae",
   "metadata": {},
   "source": [
    "# 6.1 Clean List of Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf0f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_flags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "dcae1900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_flags(entities):\n",
    "     return [e for e in entities if e not in red_flags]\n",
    "\n",
    "def lemmatizer(entities):\n",
    "    if len(entities) == 0:\n",
    "        return []\n",
    "    new = []\n",
    "    for sent in entities:\n",
    "        doc = nlp(sent.lower())\n",
    "        new.append(' '.join([token.lemma_ for token in doc]))\n",
    "    return new\n",
    "\n",
    "def fix_terms(entities):\n",
    "    new = []\n",
    "    for i in range(0, len(entities)):\n",
    "        new.append(entities[i].lower().replace('niños', 'nnaj').replace('niñas', 'nnaj')\n",
    "                   .replace('niño', 'nnaj').replace('niña', 'nnaj')\n",
    "                   .replace('adolescentes', 'nnaj').replace('adolescente', 'nnaj')\n",
    "                   .replace('jóvenes', 'nnaj').replace('jovenes', 'NNAJ').replace('joven', 'nnaj')\n",
    "                   .replace(\"utilización\", \"uso\").replace('utilizacion', 'uso'))\n",
    "        # fix ELN\n",
    "        #if entities[i].startswith(\"ELN \"):\n",
    "         #          new[len(new) - 1] =  \"Ejército de Liberación Nacional\"\n",
    "                \n",
    "    return new\n",
    "\n",
    "def clean_list_keywords(df):\n",
    "    keywords = df.NNAJ_keywords.sum()\n",
    "    if type(keywords) == str:\n",
    "        keywords = keywords.strip(\"']['\").split(\"', '\")\n",
    "    \n",
    "    #lemmatize \n",
    "    keywords = lemmatizer(keywords)\n",
    "    \n",
    "    #fix some terms\n",
    "    keywords = fix_terms(keywords)     \n",
    "    \n",
    "    #remove duplicates in same term\n",
    "    keywords = [\" \".join(dict.fromkeys(k.split())) for k in keywords]\n",
    "                \n",
    "    #remove red flags\n",
    "    keywords = remove_flags(keywords)\n",
    "    \n",
    "    #remove blank spaces\n",
    "    keywords = [k.strip() for k in keywords]\n",
    "    print(keywords)\n",
    "    return keywords\n",
    "    \n",
    "def most_mentioned_keywords(keywords):           \n",
    "    data = { \n",
    "             'keywords': list(Counter(keywords).keys()), \n",
    "             'frequency': list(Counter(keywords).values())\n",
    "           }\n",
    "\n",
    "    counterdf = pd.DataFrame(data)\n",
    "    counterdf = counterdf.groupby('keywords').agg({'frequency' : 'sum'}).sort_values('frequency', ascending = False)\n",
    "    return counterdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8187fb3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [182]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dfa \u001b[38;5;241m=\u001b[39m most_mentioned_keywords(\u001b[43mclean_list_keywords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[1;32mIn [181]\u001b[0m, in \u001b[0;36mclean_list_keywords\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     30\u001b[0m     keywords \u001b[38;5;241m=\u001b[39m keywords\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m][\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#lemmatize \u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m keywords \u001b[38;5;241m=\u001b[39m \u001b[43mlemmatizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#fix some terms\u001b[39;00m\n\u001b[0;32m     36\u001b[0m keywords \u001b[38;5;241m=\u001b[39m fix_terms(keywords)     \n",
      "Input \u001b[1;32mIn [181]\u001b[0m, in \u001b[0;36mlemmatizer\u001b[1;34m(entities)\u001b[0m\n\u001b[0;32m      7\u001b[0m new \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m entities:\n\u001b[1;32m----> 9\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     new\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([token\u001b[38;5;241m.\u001b[39mlemma_ \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc]))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py:1020\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1020\u001b[0m     doc \u001b[38;5;241m=\u001b[39m proc(doc, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomponent_cfg\u001b[38;5;241m.\u001b[39mget(name, {}))  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:253\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:274\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\model.py:315\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\ml\\tb_framework.py:33\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model, X, is_train):\n\u001b[1;32m---> 33\u001b[0m     step_model \u001b[38;5;241m=\u001b[39m \u001b[43mParserStepModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43munseen_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43munseen_classes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_upper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhas_upper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step_model, step_model\u001b[38;5;241m.\u001b[39mfinish_steps\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\ml\\parser_model.pyx:220\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\ml\\parser_model.pyx:359\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.precompute_hiddens.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\ml\\_precomputable_affine.py:27\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Preallocate array for layer output, including padding.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m Yf \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39malloc2f(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, nF \u001b[38;5;241m*\u001b[39m nO \u001b[38;5;241m*\u001b[39m nP, zeros\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 27\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgemm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnF\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnO\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnI\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mYf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m Yf \u001b[38;5;241m=\u001b[39m Yf\u001b[38;5;241m.\u001b[39mreshape((Yf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], nF, nO, nP))\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Set padding. Padding has shape (1, nF, nO, nP). Unfortunately, we cannot\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# change its shape to (nF, nO, nP) without breaking existing models. So\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# we'll squeeze the first dimension here.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dfa = most_mentioned_keywords(clean_list_keywords(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca81d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfa[dfa.frequency > 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aab6a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9d1e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfa[dfa.frequency > 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97080f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c890fc57",
   "metadata": {},
   "source": [
    "# 6. Export HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "83442c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 7_NNA.ipynb to html\n",
      "[NbConvertApp] Writing 651592 bytes to 7_NNA.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html 7_NNA.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ca885c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
